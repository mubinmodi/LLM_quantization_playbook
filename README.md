# LLM_quantization_playbook

Model weights are available on hugging face
-https://huggingface.co/Mubinmodi007/Llama-3.2-1B-finetuned
-https://huggingface.co/Mubinmodi007/Llama-3.2-1B-AWQ-4bit

LLM_Quant_testing_accuarcy.ipynb- Contains testing and benchmarking code and an explanation of my approach and issues
LLMquant_AWQ.ipynb-Contains quantization with AWQ code
llama3.2_QAT.ipynb-Contains quantization with lora code
